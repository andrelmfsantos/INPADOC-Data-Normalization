{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "<img align=\"center\" width=\"900\" src=\"https://raw.githubusercontent.com/andrelmfsantos/INPADOC-Data-Normalization/main/Images/FAPESP_Header_Google_Colab_english.png\">\n",
        "</pre>\n",
        "\n",
        "> * __INPADOC: International Patent Documentation__\n",
        "* [FAPESP Process Number: 23/12389-1](https://bv.fapesp.br/pt/auxilios/113767/solucoes-diagnosticas-e-terapeuticas-da-covid-19-protegidas-por-patentes-sistematizacao-das-principa/)"
      ],
      "metadata": {
        "id": "syI1gxktZjuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|   |   |\n",
        "|--:|:--|\n",
        "|**Authors:**|[Priscila Rezende da Costa](https://bv.fapesp.br/pt/pesquisador/67192/priscila-rezende-da-costa/) $-$ [Camila Naves Arantes](http://lattes.cnpq.br/3897204543440920) $-$ [Alex Fabianne de Paulo](http://lattes.cnpq.br/9690861410844635) $-$ </br> [Geciane Silveira Porto](https://bv.fapesp.br/pt/pesquisador/89388/geciane-silveira-porto/) $-$ [André Luis Marques Ferreira dos Santos](http://lattes.cnpq.br/9690861410844635) $-$ [Celise Marson](http://lattes.cnpq.br/2618279063609476)|\n",
        "|**Host Institution:**|[Universidade Nove de Julho (UNINOVE). Campus Vergueiro. São Paulo , SP, Brasil](https://bv.fapesp.br/pt/instituicao/1496/campus-vergueiro/)|\n",
        "|**Date:**|July 28, 2024|"
      ],
      "metadata": {
        "id": "a5LtxQdsZnC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24,986 results from Derwent Innovations Index for:**\n",
        "\n",
        "* Query:\n",
        "\n",
        "    * TS=(\"covid\" OR \"coronavirus\" OR \"pandemic\" OR \"sars-cov-2\")\n",
        "* [Derwent $-$ Web of Science](https://www.webofscience.com/wos/diidw/summary/e80a62ba-ad88-42d0-a179-f69a58eb4087-fe8523ab/diidw-relevance/1)\n",
        "* Export: \"Tab delimited file\"\n",
        "* Record Content: Full Record\n",
        "\n",
        "**Github files**:\n",
        "\n",
        "* Exports_Web_of_Science_FY2019 :: savedrecs[0]\n",
        "* Exports_Web_of_Science_FY2020 :: savedrecs[1 - 3]\n",
        "* Exports_Web_of_Science_FY2021 :: savedrecs[4 - 10]\n",
        "* Exports_Web_of_Science_FY2022 :: savedrecs[11 - 18]\n",
        "* Exports_Web_of_Science_FY2023 :: savedrecs[19 - 24]\n",
        "* Exports_Web_of_Science_FY2024 :: savedrecs[25 - 26]"
      ],
      "metadata": {
        "id": "AYyCz5spZ1bD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About this Notebook:**\n",
        "\n",
        "1. **Library Imports:**\n",
        "   - `pandas`: For data manipulation.\n",
        "   - `os`: For file system operations.\n",
        "   - `requests`: For making HTTP requests.\n",
        "   - `zipfile`: For creating zip files.\n",
        "\n",
        "2. **Directory Creation:**\n",
        "   - Checks if the directory `TXT_Web_of_Science_to_CSV` exists and creates it if it doesn't.\n",
        "\n",
        "3. **Base URL Configuration:**\n",
        "   - Sets the base URL for accessing the files hosted on GitHub.\n",
        "\n",
        "4. **Column Definition:**\n",
        "   - List of column names to be used when creating DataFrames.\n",
        "\n",
        "5. **Dictionary of Folders and Files:**\n",
        "   - Maps folder names to lists of corresponding text files.\n",
        "\n",
        "6. **Function to Read Files and Create DataFrame:**\n",
        "   - Downloads the file from the URL.\n",
        "   - Removes the BOM character from the first line if present.\n",
        "   - Splits lines by tab characters and creates a list of dictionaries.\n",
        "   - Constructs a DataFrame from the extracted data.\n",
        "\n",
        "7. **Iteration over Folders and Files:**\n",
        "   - For each folder and file listed in the dictionary:\n",
        "     - Constructs the complete file URL.\n",
        "     - Attempts to read the file and create a DataFrame.\n",
        "     - Prints the number of rows in the DataFrame.\n",
        "     - Saves the DataFrame to a CSV file in the output directory.\n",
        "     - Prints a confirmation message of the save or an error message if the download fails.\n",
        "\n",
        "8. **Creating a Zip File:**\n",
        "   - Creates a zip file containing all the generated CSV files.\n",
        "\n",
        "9. **Downloading the Zip File:**\n",
        "   - Uses Google Colab to provide a download link for the zip file."
      ],
      "metadata": {
        "id": "zPSfuhbGaLTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Ensure the output directory exists\n",
        "output_folder_path = 'TXT_Web_of_Science_to_CSV'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "# Base URL for the files on GitHub\n",
        "base_url = 'https://raw.githubusercontent.com/andrelmfsantos/INPADOC-Data-Normalization/main/Exports_Web_of_Science_Full_Years/'\n",
        "\n",
        "# Define column names\n",
        "columns = ['PN', 'TI', 'AU', 'AE', 'GA', 'AB', 'TF', 'EA', 'DC', 'MC', 'IP', 'PD', 'AD', 'FD', 'PI', 'DS', 'FS', 'CP', 'CR', 'DN', 'MN', 'RI', 'CI', 'RG']\n",
        "\n",
        "# Dictionary with folder names and respective file ranges\n",
        "folders_files = {\n",
        "    \"Exports_Web_of_Science_FY2019\": [\"savedrecs_0.txt\"],\n",
        "    \"Exports_Web_of_Science_FY2020\": [f\"savedrecs_{i}.txt\" for i in range(1, 4)],\n",
        "    \"Exports_Web_of_Science_FY2021\": [f\"savedrecs_{i}.txt\" for i in range(4, 11)],\n",
        "    \"Exports_Web_of_Science_FY2022\": [f\"savedrecs_{i}.txt\" for i in range(11, 19)],\n",
        "    \"Exports_Web_of_Science_FY2023\": [f\"savedrecs_{i}.txt\" for i in range(19, 25)],\n",
        "    \"Exports_Web_of_Science_FY2024\": [f\"savedrecs_{i}.txt\" for i in range(25, 27)]\n",
        "}\n",
        "\n",
        "# Function to read a file from a URL and return a DataFrame\n",
        "def read_file_to_dataframe(file_url):\n",
        "    response = requests.get(file_url)\n",
        "    response.raise_for_status()  # Ensure we notice bad responses\n",
        "    lines = response.text.splitlines()\n",
        "    if lines:\n",
        "        lines[0] = lines[0].replace('\\ufeff', '')  # Strip BOM character if present\n",
        "\n",
        "        # Split lines by tab and create a list of dictionaries\n",
        "        data = []\n",
        "        for line in lines[1:]:  # Skip header line\n",
        "            split_line = line.split('\\t')\n",
        "            entry = {col: split_line[i] if i < len(split_line) else None for i, col in enumerate(columns)}\n",
        "            data.append(entry)\n",
        "\n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(data, columns=columns)\n",
        "        return df\n",
        "    else:\n",
        "        return pd.DataFrame(columns=columns)\n",
        "\n",
        "# Iterate over each folder and file\n",
        "for folder, files in folders_files.items():\n",
        "    for file_name in files:\n",
        "        file_url = f\"{base_url}{folder}/{file_name}\"\n",
        "        try:\n",
        "            df = read_file_to_dataframe(file_url)\n",
        "            print(f'{file_name}: {len(df)} rows')\n",
        "\n",
        "            # Save DataFrame to CSV\n",
        "            #output_file_path = os.path.join(output_folder_path, f'{folder}_{file_name.replace(\".txt\", \".csv\")}') # join folder name + file name to export\n",
        "            output_file_path = os.path.join(output_folder_path, f'{file_name.replace(\".txt\", \".csv\")}') # only file name to export\n",
        "            df.to_csv(output_file_path, index=False)\n",
        "            print(f'Saved {output_file_path}')\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f'Failed to download {file_url}: {e}')\n",
        "\n",
        "# Zip the folder containing CSV files\n",
        "zip_file = 'TXT_Web_of_Science_to_CSV.zip'\n",
        "with ZipFile(zip_file, 'w') as zipf:\n",
        "    for root, _, files in os.walk(output_folder_path):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n",
        "\n",
        "print(f\"Created zip file: {zip_file}\")\n",
        "\n",
        "# Provide a link to download the zipped folder\n",
        "from google.colab import files\n",
        "files.download(zip_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "koArYjznTHUo",
        "outputId": "94cb54ca-c369-4f53-98c0-91a27a63219e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "savedrecs_0.txt: 194 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_0.csv\n",
            "savedrecs_1.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_1.csv\n",
            "savedrecs_2.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_2.csv\n",
            "savedrecs_3.txt: 427 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_3.csv\n",
            "savedrecs_4.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_4.csv\n",
            "savedrecs_5.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_5.csv\n",
            "savedrecs_6.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_6.csv\n",
            "savedrecs_7.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_7.csv\n",
            "savedrecs_8.txt: 968 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_8.csv\n",
            "savedrecs_9.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_9.csv\n",
            "savedrecs_10.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_10.csv\n",
            "savedrecs_11.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_11.csv\n",
            "savedrecs_12.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_12.csv\n",
            "savedrecs_13.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_13.csv\n",
            "savedrecs_14.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_14.csv\n",
            "savedrecs_15.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_15.csv\n",
            "savedrecs_16.txt: 948 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_16.csv\n",
            "savedrecs_17.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_17.csv\n",
            "savedrecs_18.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_18.csv\n",
            "savedrecs_19.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_19.csv\n",
            "savedrecs_20.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_20.csv\n",
            "savedrecs_21.txt: 674 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_21.csv\n",
            "savedrecs_22.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_22.csv\n",
            "savedrecs_23.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_23.csv\n",
            "savedrecs_24.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_24.csv\n",
            "savedrecs_25.txt: 1000 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_25.csv\n",
            "savedrecs_26.txt: 775 rows\n",
            "Saved TXT_Web_of_Science_to_CSV/savedrecs_26.csv\n",
            "Created zip file: TXT_Web_of_Science_to_CSV.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7d491828-248d-4495-892d-3f0d90827e5c\", \"TXT_Web_of_Science_to_CSV.zip\", 317998200)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}